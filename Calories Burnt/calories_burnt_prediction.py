# -*- coding: utf-8 -*-
"""Calories Burnt Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dx_HuY5sz0MWOeJWSkjaYqswkE40pIcV
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn import metrics
from sklearn.svm import SVC
from xgboost import XGBRegressor
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.ensemble import RandomForestRegressor

import warnings
warnings.filterwarnings('ignore')

import pandas as pd

df_calories = pd.read_csv(r"/content/calories.csv")
df_exercise = pd.read_csv(r"/content/exercise.csv")

print(df_calories.head())
print(df_exercise.head())
df = pd.merge(df_calories, df_exercise, on='User_ID')
print(df)

print("Data Information")
df.info()

df.describe()

# check for missing values
print(df.sum())

df = pd.get_dummies(df, columns=['Gender'], drop_first=True)

# dataframe after encoding 'gender' column
print(df.head())

sb.scatterplot(x='Height', y='Weight', data=df)
plt.show()

# the distribution of the continuous features
features = df.select_dtypes(include='float').columns

plt.subplots(figsize=(15, 10))
for i, col in enumerate(features):
    plt.subplot(2, 3, i+1)
    sb.distplot(df[col])
plt.tight_layout()
plt.show()

"""Feature Selection & Model Training"""

X = df.drop(columns=['User_ID', 'Calories'])
y = df['Calories']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"Data split into {X_train.shape[0]} training samples and {X_test.shape[0]} testing samples.")

model = XGBRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

"""Model Evaluation"""

from sklearn.metrics import mean_absolute_error, r2_score

y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"R-squared (RÂ²): {r2:.4f}")

# visualizing the difference between actual and predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.6, edgecolors='w', s=50)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
plt.title("Actual vs. Predicted Calories")
plt.show() # The closer the blue dots are to the red dashed line, the better the model's predictions